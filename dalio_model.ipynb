{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERIOD = \"1y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FMF.WA: No data found, symbol may be delisted\n",
      "LVC.WA: No data found, symbol may be delisted\n",
      "AML.WA: No data found, symbol may be delisted\n",
      "BML.WA: No data found, symbol may be delisted\n",
      "R22.WA: No data found, symbol may be delisted\n"
     ]
    }
   ],
   "source": [
    "WIG20 = [\"ACP\", \"ALE\", \"CCC\", \"CDR\", \"CPS\", \"DNP\", \"JSW\", \"KGH\", \"KRU\", \"KTY\", \"LPP\", \"MBK\", \"OPL\", \"PCO\", \"PEO\", \"PGE\", \"PKN\", \"PKO\", \"PZU\", \"SPL\"]\n",
    "\n",
    "WIG40 = [\"11B\", \"ALR\", \"APR\", \"ASB\", \"ATT\", \"BDX\", \"BFT\", \"BHW\", \"BMC\", \"CAR\", \"CIE\", \"CMR\", \"DAT\", \"DOM\", \"DVL\", \"EAT\", \"ENA\", \"EUR\", \"FMF\", \"GPP\",\n",
    "         \"GPW\", \"HUG\", \"ING\", \"KER\", \"LVC\", \"LWB\", \"MAB\", \"MBR\", \"MIL\", \"MRC\", \"NEU\", \"PEP\", \"PKP\", \"SLV\", \"STH\", \"TEN\", \"TPE\", \"WPL\", \"XTB\", \"ZEP\"]\n",
    "\n",
    "WIG80 = [\"1AT\", \"ABE\", \"ACG\", \"ACT\", \"AGO\", \"AMB\", \"AMC\", \"AML\", \"APT\", \"ARH\", \"ASE\", \"AST\", \"ATC\", \"ATG\", \"BIO\", \"BML\", \"BNP\", \"BOS\", \"BOW\", \"BRS\",\n",
    "         \"CAV\", \"CIG\", \"CLE\", \"CLN\", \"CMP\", \"COG\", \"CRJ\", \"CTX\", \"DCR\", \"ECH\", \"ENT\", \"ERB\", \"FRO\", \"FTE\", \"GRN\", \"GTN\", \"IMC\", \"INK\", \"KGN\", \"LBW\",\n",
    "         \"MCI\", \"MLS\", \"MOC\", \"MRB\", \"NWG\", \"OND\", \"OPN\", \"PBX\", \"PCF\", \"PCR\", \"PEN\", \"PHN\", \"PLW\", \"PXM\", \"R22\", \"RBW\", \"RFK\", \"RVU\", \"RWL\", \"SCP\",\n",
    "         \"SEN\", \"SGN\", \"SHO\", \"SKA\", \"SNK\", \"SNT\", \"SNX\", \"STP\", \"STX\", \"TIM\", \"TOA\", \"TOR\", \"UNT\", \"VGO\", \"VOT\", \"VOX\", \"VRC\", \"VRG\", \"WLT\", \"WWL\"]\n",
    "\n",
    "TICKERS = WIG80 + WIG40 + WIG20\n",
    "\n",
    "dfs_wig20 = []\n",
    "dfs_wig40 = []\n",
    "dfs_wig80 = []\n",
    "\n",
    "for company in WIG20:\n",
    "    ticker = yf.Ticker(company + \".WA\")\n",
    "    dfs_wig20.append(ticker.history(period=PERIOD))\n",
    "\n",
    "for company in WIG40:\n",
    "    ticker = yf.Ticker(company + \".WA\")\n",
    "    dfs_wig40.append(ticker.history(period=PERIOD))\n",
    "\n",
    "for company in WIG80:\n",
    "    ticker = yf.Ticker(company + \".WA\")\n",
    "    dfs_wig80.append(ticker.history(period=PERIOD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCIES = [\"EURUSD\", \"USDPLN\", \"EURPLN\", \"GBPUSD\", \"USDJPY\"]\n",
    "\n",
    "dfs_currencies = []\n",
    "for currency in CURRENCIES:\n",
    "    c = yf.Ticker(currency+\"=X\")\n",
    "    dfs_currencies.append(c.history(period=PERIOD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEXES = [\"^GSPC\", \"^IXIC\", \"^GDAXI\", \"^FTSE\", \"^N225\"]\n",
    "\n",
    "dfs_indexes = []\n",
    "for index in INDEXES:\n",
    "    i = yf.Ticker(index)\n",
    "    dfs_indexes.append(i.history(period=PERIOD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NATURAL_RESOURCES = [\"CL=F\", \"CB=F\", \"NG=F\", \"GC=F\", \"SI=F\", \"HG=F\", \"ZC=F\", \"HDG=F\"]\n",
    "\n",
    "dfs_resources = []\n",
    "for resource in NATURAL_RESOURCES:\n",
    "    n = yf.Ticker(\"GC=F\")\n",
    "    dfs_resources.append(n.history(period=PERIOD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRICES = TICKERS + NATURAL_RESOURCES + CURRENCIES + INDEXES\n",
    "\n",
    "dfs = dfs_wig20 + dfs_wig40 + dfs_wig80 + dfs_resources + dfs_currencies + dfs_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(PRICES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlcv = []\n",
    "\n",
    "for df in dfs:\n",
    "    df = df[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
    "    ohlcv.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251 251\n",
      "251 251\n",
      "251 251\n",
      "251 251\n",
      "251 251\n",
      "251 251\n",
      "251 252\n",
      "251 251\n",
      "251 251\n",
      "251 251\n",
      "251 251\n",
      "251 251\n",
      "251 251\n",
      "251 251\n",
      "251 252\n",
      "251 251\n",
      "251 252\n",
      "251 251\n",
      "251 251\n",
      "251 251\n",
      "251 251\n",
      "251 251\n",
      "251 251\n",
      "251 251\n",
      "251 251\n",
      "251 252\n",
      "251 251\n",
      "251 251\n",
      "251 251\n",
      "250 252\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 252\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 252\n",
      "250 251\n",
      "250 252\n",
      "250 251\n",
      "250 251\n",
      "250 252\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 253\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 252\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 252\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 252\n",
      "250 251\n",
      "250 251\n",
      "250 252\n",
      "250 251\n",
      "250 251\n",
      "250 252\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n",
      "250 251\n"
     ]
    }
   ],
   "source": [
    "idx = ohlcv[0].index\n",
    "\n",
    "#Hacky, idk why this does not work\n",
    "\n",
    "for df in ohlcv[1:133]:\n",
    "    if df.index.size > 0:\n",
    "        idx = idx.intersection(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "common = []\n",
    "\n",
    "for df in ohlcv:\n",
    "    common.append(df.reindex(index=idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "158 prices * 5 variables for each day (250 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = []\n",
    "names = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "\n",
    "for price in common:\n",
    "    vec = []\n",
    "    for value in names:\n",
    "        curr = price[value]\n",
    "        mean = curr.mean()\n",
    "        std = curr.std()\n",
    "\n",
    "        normalized = (curr - mean) / std\n",
    "        vec.append(normalized)\n",
    "    \n",
    "    normal.append(pd.concat(vec, axis=1, names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2023-01-09 00:00:00+01:00   -0.996601\n",
       "2023-01-10 00:00:00+01:00   -1.254271\n",
       "2023-01-11 00:00:00+01:00   -1.671453\n",
       "2023-01-12 00:00:00+01:00   -1.585562\n",
       "2023-01-13 00:00:00+01:00   -1.745070\n",
       "                               ...   \n",
       "2023-12-29 00:00:00+01:00   -0.891506\n",
       "2024-01-02 00:00:00+01:00   -1.173183\n",
       "2024-01-03 00:00:00+01:00   -1.237200\n",
       "2024-01-04 00:00:00+01:00   -1.288413\n",
       "2024-01-05 00:00:00+01:00   -0.865900\n",
       "Name: Close, Length: 250, dtype: float64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal[0]['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 790)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = np.nan_to_num(np.swapaxes(np.stack(normal), 0, 1).reshape(250, 158*5), copy=True, nan=0.0)\n",
    "\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "layer = nn.TransformerEncoderLayer(d_model=790, nhead=10)\n",
    "model = nn.TransformerEncoder(layer, num_layers=3)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters())\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def src_mask(sz):\n",
    "  mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "  mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "  \n",
    "  return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Iter:\n",
    "    def __init__(self, dataset):\n",
    "        self.data = dataset\n",
    "        self.idx = 0\n",
    "\n",
    "    def inc(self):\n",
    "        self.idx += 1\n",
    "\n",
    "        return self.idx\n",
    "\n",
    "    def __next__(self):\n",
    "        idx = self.inc()\n",
    "\n",
    "        if idx >= self.data.shape[0]:\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            return self.data[idx - 1], self.data[idx]\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 790) (125, 790)\n"
     ]
    }
   ],
   "source": [
    "train, test = np.array_split(dataset, 2)\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.7743169069290161\n"
     ]
    }
   ],
   "source": [
    "test_loss_after = []\n",
    "\n",
    "iter_test = Iter(test)\n",
    "test_seq = torch.zeros(790).unsqueeze(0)\n",
    "\n",
    "for x, y in iter_test:\n",
    "    inp = torch.reshape(torch.tensor(x, dtype=torch.float), (790,)).unsqueeze(0).nan_to_num(nan=0.0)\n",
    "    test_seq = torch.cat((test_seq, inp), dim=0).nan_to_num(nan=0.0)\n",
    "    y_hat = model(test_seq, src_mask(790)).squeeze().to(torch.float32)\n",
    "    y = torch.reshape(torch.tensor(y).to(torch.float32), (790,))\n",
    "    pred = y_hat[0]\n",
    "    pred = pred.nan_to_num(nan=0.0)\n",
    "    y = y.nan_to_num(nan=0.0)\n",
    "\n",
    "    loss = loss_function(pred[::2], y[::2])\n",
    "\n",
    "    test_loss_after.append(loss.item())\n",
    "\n",
    "print(\"Test loss: \", sum(test_loss_after) / len(test_loss_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.4181289706499346\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "\n",
    "iter_train = Iter(train)\n",
    "train_seq = torch.zeros(790).unsqueeze(0)\n",
    "\n",
    "for x, y in iter_train:\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    inp = torch.reshape(torch.tensor(x, dtype=torch.float), (790,)).unsqueeze(0).nan_to_num(nan=0.0)\n",
    "    test_seq = torch.cat((test_seq, inp), dim=0).nan_to_num(nan=0.0)\n",
    "    y_hat = model(test_seq, src_mask(790)).squeeze().to(torch.float32)\n",
    "    y = torch.reshape(torch.tensor(y).to(torch.float32), (790,))\n",
    "    pred = y_hat[0]\n",
    "    pred = pred.nan_to_num(nan=0.0)\n",
    "    y = y.nan_to_num(nan=0.0)\n",
    "\n",
    "    loss = loss_function(pred[::2], y[::2])\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    train_loss.append(loss.item())\n",
    "\n",
    "print(\"Train loss: \", sum(train_loss) / len(train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  1.0440861210227013\n"
     ]
    }
   ],
   "source": [
    "test_loss_after = []\n",
    "\n",
    "iter_test = Iter(test)\n",
    "test_seq = torch.zeros(790).unsqueeze(0)\n",
    "\n",
    "for x, y in iter_test:\n",
    "    inp = torch.reshape(torch.tensor(x, dtype=torch.float), (790,)).unsqueeze(0).nan_to_num(nan=0.0)\n",
    "    test_seq = torch.cat((test_seq, inp), dim=0).nan_to_num(nan=0.0)\n",
    "    y_hat = model(test_seq, src_mask(790)).squeeze().to(torch.float32)\n",
    "    y = torch.reshape(torch.tensor(y).to(torch.float32), (790,))\n",
    "    pred = y_hat[0]\n",
    "    pred = pred.nan_to_num(nan=0.0)\n",
    "    y = y.nan_to_num(nan=0.0)\n",
    "\n",
    "    loss = loss_function(pred[::2], y[::2])\n",
    "\n",
    "    test_loss_after.append(loss.item())\n",
    "\n",
    "print(\"Test loss: \", sum(test_loss_after) / len(test_loss_after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No importance masking implemented "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
